# 期末各項作業說明
習題解答大部分均來自詢問chatgpt，在各部分不再做此備注。如有參考老師的範例或者同學的解答的題目，或者是gpt解釋後我依然理解不了的題目，會在對應的習題段落說明。<br>對各個習題，在詢問gpt的同時，我有要求他說明其解答的原理、做法和目的，以此了解各個作業的重點和原理。我對大部分習題的理解達到90%，並能對其進行介紹和說明。
## hw1
此題目中的函數是壹個凸函數，也就是單峰函數，可透過梯度下降或局部搜索快速收斂，習題要求使用爬山演算法，其邏輯是不斷尋找更小的鄰近解，直到找不到更優解爲止。其使用方法爲：首先設定初始點，然後定義鄰居。如果鄰居比當前的點更好，就接受鄰居並繼續前進，否則就停機。

## hw2
習題二要求使用爬山演算法解決旅行推銷員問題TSP。其原理是，因爲TSP　是　NP-hard　問題，無法用窮舉法求解大規模實例，所以選擇用鄰域優化策略進行局部改進，而爬山法用于持續嘗試更短路徑直到穩定。<br/>其使用方法爲，以城市列表生成路徑，以路徑總長作爲評估指標，然後定義鄰居並尋找改善解，可以用　2-opt　或　swap　策略定義鄰域

## hw3
本題的解答來自gpt。據gpt所說，這是壹個偏導數與梯度的問題。我必須說我記住了邏輯，要分別對x和y做偏導，將梯度記爲向量形式，但是基本沒有理解。我根本就不會算這種問題。

## hw4
本題有參考老師提供的“gpt錯誤內容”和github中的參考。<br/>
根據老師提供的內容和題目的描述，本體的要求爲：利用多層感知器（MLP）模型，使用數值梯度下降法來學習，輸入七段顯示器亮滅狀態，輸出代表數字的　4-bit　二進制碼<br>
而老師提供的代碼的錯誤或者說跟本題目的區別部分在于：第壹，不是MLP。因爲它沒有隱藏層，執行的只是線性變換。<br>第二，沒有激活函數（ReLU　/　Sigmoid）。這部分錯誤代碼中全程沒有如下內容
```
z1　=　np.dot(input,　W1)　+　b1
a1　=　sigmoid(z1)　　#　或　relu
z2　=　np.dot(a1,　W2)　+　b2
```
本題搭建含　Sigmoid　激活的　MLP，使用　compute_numerical_gradient()　實作手動梯度下降，在每輪　epoch　後更新參數並輸出　loss

## hw5
本題是在模擬神經網絡每壹層的梯度傳播過程，每個節點的輸出對最終結果的偏導數由鏈式法則推導得出。所以，需要畫出計算圖，將自變量帶入計算正向傳播，並從輸出反推各變量梯度

## hw6
本題參考了同學的代碼，並通過詢問chatgpt代碼各部分執行的內容和目的了解代碼。<br>本題的原理是，micrograd　使用計算圖　+　鏈式法則，記錄每個　Value　對象的操作與梯度傳播路徑。在定義新函數時，forward　pass　要生成新的節點，並在　.backward()　時　根據鏈式法則傳梯度。在作業的代碼中，已經實現了題目要求，並且每個操作都有對應的　_backward()　實作，確保鏈式法則能正確執行，以及使用　math.exp()　，符合　micrograd　的結構，也就是只依賴標准庫

## hw7
本題的做法是，需要micrograd　自動構建計算圖並計算偏導數，梯度下降則使用θ=θ-η·∇f來反複更新參數。

## hw8
本題和上壹題壹樣，目的是優化壹個三變量凸函數。區別在于，　PyTorch　的　torch.Tensor　需要搭配　.backward()　自動求導，同時，使用　PyTorch　內建的　.grad、.item()　等接口能更方便地追蹤值與導數

## hw9
線性回歸是最基本的監督學習方法，利用　MSE（均方誤差）作爲損失函數，模型參數　𝑤、w、𝑏、b　通過　autograd　自動反向傳播優化。以我的代碼來說，最終訓練出的參數w≈2，b≈3，Loss　趨近于　0。

## hw10
本題詢問gpt具體做法，代碼的部分參考老師給的參考。

## hw11
本題的各個py中均有標注使用的資料集，在此作統壹說明。
| 類型 | 方法                 | 資料集                | 評估指標            | 關鍵步驟                    |
| -- | ------------------ | ------------------ | --------------- | ----------------------- |
| 分類 | LogisticRegression | `load_digits()`    | Accuracy        | 預測數字 0\~9               |
| 分群 | KMeans             | `make_blobs()`     | 無 label → 視覺化驗證 | 設定 k, 比對視覺群聚結果          |
| 回歸 | LinearRegression   | California Housing | MSE             | 房價預測，目標變數為 median price |

## hw12
未完成

## hw13
DBSCAN。詳情請見對應文件夾下的說明檔案。

## hw14
参考了同学的脚本中的做法，最终决定使用加权控制策略 + 非线性响应，能够动态判断当前状态是：稳定区域还是偏移区域，综合考虑、杆角（pole angle）、杆角速度（angular velocity）、车位置（cart position）、车速度（cart velocity）。具体请检视对应文件夹下的md档案。

## 期中作业
详见midterm下文件夹的Readme.md
